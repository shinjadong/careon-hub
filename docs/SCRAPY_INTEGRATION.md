# Scrapy í†µí•© ì™„ë£Œ - CareOn Hub

> **ì‘ì—… ì™„ë£Œì¼**: 2026-01-16
> **í†µí•© ëª¨ë“ˆ**: Scrapy + ADB ë””ë°”ì´ìŠ¤ ì œì–´

---

## ğŸ“‹ í†µí•© ê°œìš”

CareOn Hubì— **Scrapy ì›¹ ìŠ¤í¬ë˜í•‘** ê¸°ëŠ¥ì´ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ ì œì–´(ADB)ì™€ í•¨ê»˜ ì‘ë™í•˜ì—¬ ì›¹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ì—ì„œ ì§ì ‘ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### 1. **6ê°œì˜ í”„ë¡œë•ì…˜ê¸‰ ìŠ¤íŒŒì´ë”**

| ìŠ¤íŒŒì´ë” | ì„¤ëª… | íƒ€ì… | í•„ìˆ˜ ì¸ì |
|---------|------|------|----------|
| `naver_news` | ë„¤ì´ë²„ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ | basic | ì—†ìŒ |
| `naver_news_detail` | ë„¤ì´ë²„ ë‰´ìŠ¤ ìƒì„¸ ê¸°ì‚¬ | basic | article_url |
| `mobile_web` | ëª¨ë°”ì¼ ì›¹ í˜ì´ì§€ | playwright | url |
| `instagram_mobile` | Instagram í”„ë¡œí•„ | playwright | username |
| `dynamic_content` | ë™ì  JavaScript ì½˜í…ì¸  | playwright | url |
| `api_scraper` | API ì‘ë‹µ ì¸í„°ì…‰íŠ¸ | playwright | url, api_pattern |

### 2. **í†µí•© íŒŒì´í”„ë¼ì¸**

- âœ… **CareonScraperPipeline**: ë°ì´í„° ì •ì œ ë° ê²€ì¦
- âœ… **ADBIntegrationPipeline**: ADB ë””ë°”ì´ìŠ¤ ì œì–´ í†µí•©
- âœ… **SupabasePipeline**: Supabase ë°ì´í„°ë² ì´ìŠ¤ ìë™ ì €ì¥
- âœ… **JSONFilePipeline**: ë¡œì»¬ JSON ë°±ì—…

### 3. **ê³ ê¸‰ ê¸°ëŠ¥**

- ğŸ”„ **User-Agent ë¡œí…Œì´ì…˜**: ë‹¤ì–‘í•œ ë¸Œë¼ìš°ì €/ë””ë°”ì´ìŠ¤ ì—ë®¬ë ˆì´ì…˜
- ğŸ­ **Playwright í†µí•©**: JavaScript ë Œë”ë§, ë¬´í•œ ìŠ¤í¬ë¡¤ ì§€ì›
- ğŸ“± **ëª¨ë°”ì¼ ì—ë®¬ë ˆì´ì…˜**: iPhone/Android ë·°í¬íŠ¸ ì„¤ì •
- ğŸ’¾ **HTTP ìºì‹±**: ê°œë°œ ì‹œ ë¹ ë¥¸ ë°˜ë³µ
- âš¡ **Auto-Throttle**: ìë™ ì†ë„ ì¡°ì ˆë¡œ ì„œë²„ ë¶€í•˜ ìµœì†Œí™”

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1ï¸âƒ£ ê¸°ë³¸ ìŠ¤í¬ë˜í•‘

```bash
cd backend/app/core/scraper

# ë„¤ì´ë²„ ë‰´ìŠ¤
scrapy crawl naver_news

# ëª¨ë°”ì¼ ì›¹
scrapy crawl mobile_web -a url=https://m.naver.com

# Instagram
scrapy crawl instagram_mobile -a username=instagram
```

### 2ï¸âƒ£ Pythonì—ì„œ ì‚¬ìš©

```python
from app.core.scraper.scraper_manager import ScraperManager

manager = ScraperManager()
manager.run_spider("naver_news")
```

### 3ï¸âƒ£ ADBì™€ í†µí•© ì‚¬ìš©

```python
from app.core.scraper.scraper_manager import ADBScraperIntegration

integration = ADBScraperIntegration()
result = integration.scrape_and_open_on_device(
    "mobile_web",
    device_serial="RF8NA0ABCDE",
    spider_args={"url": "https://m.naver.com"}
)
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
backend/app/core/scraper/
â”œâ”€â”€ careon_scraper/              # Scrapy í”„ë¡œì íŠ¸
â”‚   â”œâ”€â”€ spiders/                 # ìŠ¤íŒŒì´ë”
â”‚   â”‚   â”œâ”€â”€ naver_news.py        # ë„¤ì´ë²„ ë‰´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ mobile_web.py        # ëª¨ë°”ì¼ ì›¹
â”‚   â”‚   â””â”€â”€ dynamic_content.py   # ë™ì  ì½˜í…ì¸ 
â”‚   â”œâ”€â”€ settings.py              # ì„¤ì • (ADB/Playwright í†µí•©)
â”‚   â”œâ”€â”€ pipelines.py             # íŒŒì´í”„ë¼ì¸ (ADB/Supabase)
â”‚   â”œâ”€â”€ items.py                 # ë°ì´í„° ëª¨ë¸
â”‚   â””â”€â”€ middlewares.py           # ë¯¸ë“¤ì›¨ì–´
â”œâ”€â”€ scraper_manager.py           # ê´€ë¦¬ì í´ë˜ìŠ¤
â”œâ”€â”€ scrapy.cfg                   # Scrapy ì„¤ì •
â””â”€â”€ README.md                    # ìƒì„¸ ë¬¸ì„œ
```

---

## ğŸ”§ ì„¤ì • ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì£¼ìš” ì„¤ì • íŒŒì¼: `careon_scraper/settings.py`

```python
# ADB ë””ë°”ì´ìŠ¤ í†µí•©
ADB_ENABLED = True
ADB_DEVICES_PATH = "/path/to/adb"

# Supabase í†µí•©
SUPABASE_ENABLED = True
SUPABASE_TABLE = "scraped_data"

# Playwright ëª¨ë°”ì¼ ì—ë®¬ë ˆì´ì…˜
PLAYWRIGHT_CONTEXTS = {
    "default": {
        "viewport": {"width": 412, "height": 915},
        "user_agent": "Mozilla/5.0 (Linux; Android 13...)"
    }
}

# ì„±ëŠ¥ ìµœì í™”
CONCURRENT_REQUESTS = 8
DOWNLOAD_DELAY = 2
AUTOTHROTTLE_ENABLED = True
```

---

## ğŸ’¾ ë°ì´í„° ì €ì¥

ìŠ¤í¬ë˜í•‘í•œ ë°ì´í„°ëŠ” 3ê³³ì— ìë™ ì €ì¥:

1. **Supabase**: `scraped_data` í…Œì´ë¸”
2. **ë¡œì»¬ JSON**: `/home/tlswkehd/projects/careon-hub/backend/data/scraped/`
3. **HTTP ìºì‹œ**: `httpcache/` (ê°œë°œìš©)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
cd backend
source .venv/bin/activate
python test_scraper.py
```

**í…ŒìŠ¤íŠ¸ ê²°ê³¼**:
```
âœ… ì´ 6ê°œì˜ ìŠ¤íŒŒì´ë” ë°œê²¬
âœ… ëª¨ë“  ìŠ¤íŒŒì´ë” ì •ìƒ ì‘ë™
âœ… ADB í†µí•© ì¤€ë¹„ ì™„ë£Œ
âœ… Supabase ì—°ë™ ì¤€ë¹„ ì™„ë£Œ
```

---

## ğŸ”— í†µí•© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ â†’ ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ í™•ì¸

```python
# 1. ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ìˆ˜ì§‘
integration = ADBScraperIntegration()
result = integration.scrape_and_open_on_device(
    "naver_news",
    device_serial="your-device-id"
)

# 2. ìˆ˜ì§‘í•œ URLì„ ë””ë°”ì´ìŠ¤ì—ì„œ ìë™ ì—´ê¸°
# 3. Supabaseì— ìë™ ì €ì¥
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë™ì  ì½˜í…ì¸  ìŠ¤í¬ë˜í•‘

```bash
# JavaScriptë¡œ ë Œë”ë§ë˜ëŠ” SPA ìŠ¤í¬ë˜í•‘
scrapy crawl dynamic_content -a url=https://example.com

# ë¬´í•œ ìŠ¤í¬ë¡¤ ìë™ ì²˜ë¦¬
# API ì‘ë‹µ ì¸í„°ì…‰íŠ¸
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: Instagram ë°ì´í„° ìˆ˜ì§‘

```bash
scrapy crawl instagram_mobile -a username=target_user

# ëª¨ë°”ì¼ ë·°í¬íŠ¸ ì—ë®¬ë ˆì´ì…˜
# ê³µê°œ í”„ë¡œí•„ ì •ë³´ ìˆ˜ì§‘
```

---

## ğŸ“¦ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€

```
scrapy>=2.11.0
scrapy-playwright>=0.0.34
scrapy-user-agents>=0.1.1
scrapy-rotating-proxies>=0.6.2
```

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

### 1. FastAPI ë¼ìš°í„° ì¶”ê°€

`backend/app/api/scraper.py` ìƒì„±:

```python
from fastapi import APIRouter
from app.core.scraper.scraper_manager import ScraperManager

router = APIRouter(prefix="/scraper", tags=["scraper"])

@router.post("/run")
async def run_spider(spider_name: str, url: str = None):
    manager = ScraperManager()
    result = manager.run_spider(
        spider_name,
        spider_args={"url": url} if url else None
    )
    return {"success": result}

@router.get("/spiders")
async def list_spiders():
    manager = ScraperManager()
    return {"spiders": manager.list_spiders()}
```

### 2. í”„ë¡ íŠ¸ì—”ë“œ UI ì¶”ê°€

```typescript
// frontend/src/pages/Scraper.tsx
const ScraperPage = () => {
  const [spiders, setSpiders] = useState([]);

  useEffect(() => {
    fetch('/api/scraper/spiders')
      .then(res => res.json())
      .then(data => setSpiders(data.spiders));
  }, []);

  return (
    <div>
      <h1>ì›¹ ìŠ¤í¬ë˜í•‘</h1>
      {/* ìŠ¤íŒŒì´ë” ì„ íƒ UI */}
    </div>
  );
};
```

### 3. ìŠ¤ì¼€ì¤„ë§ (Cron)

```bash
# ë§¤ì¼ ì˜¤ì „ 9ì‹œ ë‰´ìŠ¤ ìˆ˜ì§‘
0 9 * * * cd /path/to/careon-hub/backend/app/core/scraper && scrapy crawl naver_news
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- **ìƒì„¸ ë¬¸ì„œ**: `backend/app/core/scraper/README.md`
- **Scrapy ê³µì‹**: https://docs.scrapy.org/
- **Playwright í†µí•©**: https://github.com/scrapy-plugins/scrapy-playwright
- **í”„ë¡œì íŠ¸ ë©”ì¸**: `/home/tlswkehd/projects/careon-hub/README.md`

---

## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Scrapy í”„ë¡œì íŠ¸ ìƒì„±
- [x] 6ê°œ ìŠ¤íŒŒì´ë” êµ¬í˜„ (ë‰´ìŠ¤, ëª¨ë°”ì¼, ë™ì )
- [x] ADB í†µí•© íŒŒì´í”„ë¼ì¸
- [x] Supabase ì €ì¥ íŒŒì´í”„ë¼ì¸
- [x] Playwright ë™ì  ì½˜í…ì¸  ì§€ì›
- [x] User-Agent ë¡œí…Œì´ì…˜
- [x] ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ ì—ë®¬ë ˆì´ì…˜
- [x] HTTP ìºì‹±
- [x] ê´€ë¦¬ì í´ë˜ìŠ¤ (ScraperManager)
- [x] í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- [x] ë¬¸ì„œ ì‘ì„±

---

**ğŸ‰ í†µí•© ì™„ë£Œ! ì´ì œ CareOn Hubì—ì„œ ê°•ë ¥í•œ ì›¹ ìŠ¤í¬ë˜í•‘ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**
